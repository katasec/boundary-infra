package resources

import (
	"fmt"
	"log"
	"os"
	"strings"

	appsv1 "github.com/pulumi/pulumi-kubernetes/sdk/v3/go/kubernetes/apps/v1"
	corev1 "github.com/pulumi/pulumi-kubernetes/sdk/v3/go/kubernetes/core/v1"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"

	"boundary/resources/k8s"
	"boundary/utils"
)

type ContainerSpec struct {
	Name    string
	Image   string
	Command []string
	Args    []string
}

func DeployToK8s(ctx *pulumi.Context) {

	// Create namespace for boundary
	namespace, err := corev1.NewNamespace(ctx, "boundary", nil)
	utils.ExitOnError(err)
	ctx.Export("k8sNamespace", namespace.Metadata.Name())
	// Create config maps to store SSL certs and boundary config files
	CreateConfigMaps(ctx, namespace)

	// Init Boundary DB
	boundaryDbInitJob := BoundaryDbInit(ctx, namespace)
	jobName := boundaryDbInitJob.Metadata.Name().ApplyT(func(jobName *string) string {
		return *jobName
	}).(pulumi.StringOutput)

	ctx.Export("boundaryDbInitJob", jobName)

	// Create controller deployment + service + update dns
	ports := corev1.ContainerPortArray{
		corev1.ContainerPortArgs{
			ContainerPort: pulumi.Int(9200),
		},
		corev1.ContainerPortArgs{
			ContainerPort: pulumi.Int(9201),
		},
		corev1.ContainerPortArgs{
			ContainerPort: pulumi.Int(9202),
		},
	}
	controllerDeployment := BoundaryDeployer(ctx, "controller", ports, []pulumi.Resource{boundaryDbInitJob}, namespace)

	svcPorts := corev1.ServicePortArray{
		&corev1.ServicePortArgs{
			Name:       pulumi.String("api"),
			Port:       pulumi.Int(9200),
			Protocol:   pulumi.String("TCP"),
			TargetPort: pulumi.Int(9200),
		},
		&corev1.ServicePortArgs{
			Name:       pulumi.String("cluster"),
			Port:       pulumi.Int(9201),
			Protocol:   pulumi.String("TCP"),
			TargetPort: pulumi.Int(9201),
		},
	}
	controllerSvc := k8s.CreateK8Service(ctx, "boundary-controller", "boundary-controller-pulumi", "TCP", svcPorts, []pulumi.Resource{controllerDeployment}, namespace)
	controllerSvcIp := controllerSvc.Spec.ClusterIP()

	//podInfo := utils.GetPodInfoByLabel("default", "app=boundary-controller-pulumi")
	ctx.Export("controllerSvcIp", controllerSvcIp)

	controllerDns := UpdateDnsRecord(ctx, DnsZone, ControllerARecord, controllerSvcIp)

	// Create worker deployment + service + update dns
	workerDeployment := BoundaryDeployer(ctx, "worker", ports, []pulumi.Resource{boundaryDbInitJob, controllerDns}, namespace)
	workerSvcPorts := corev1.ServicePortArray{
		&corev1.ServicePortArgs{
			Name:       pulumi.String("proxy"),
			Port:       pulumi.Int(9202),
			Protocol:   pulumi.String("TCP"),
			TargetPort: pulumi.Int(9202),
		},
	}
	workerSvc := k8s.CreateK8Service(ctx, "boundary-worker", "boundary-worker-pulumi", "TCP", workerSvcPorts, []pulumi.Resource{workerDeployment}, namespace)
	workerSvcIp := workerSvc.Status.LoadBalancer().Ingress().Index(pulumi.Int(0)).Ip()
	UpdateDnsRecord(ctx, DnsZone, WorkerARecord, workerSvcIp)

	// Create Argo Argo Tunnel for controller
	cfTunnel, tunnelSecret := CreateArgoTunnel(ctx, CloudflareAccountId, CloudflareTunnelName)

	// Create Cloudflare DNS Entry
	tunnelName := fmt.Sprintf("%s.%s", CloudflareTunnelName, CloudflareDnszone)
	value := pulumi.Sprintf("%s.%s", cfTunnel.ID(), "cfargotunnel.com")
	cfRecord := CreateCloudFlareRecord(ctx, tunnelName, CloudflareZoneId, value, "CNAME")

	// Create K8s secret containing tunnel creds
	k8sSecret := NewCloudFlareTunnelSecret(ctx, pulumi.Sprintf("%s", cfTunnel.ID()), CloudflareTunnelName, tunnelSecret, CloudflareAccountId, []pulumi.Resource{cfTunnel, cfRecord}, namespace)

	// Create Deployment for cloudflared to setup reverse tunnel
	DeployCFtunnel(ctx, "argotunnel", k8sSecret, namespace)

	// Create a Deployment for ngrok for a reverse TCP proxy on the cloud edge
	// edgeLabel := "edgtcp_2CTAtrLS79D6NE7yRh3ka006foE"
	// ngrokTunnel := "2DU6B4w3wZkgFkZNE9Tan5DMICT_3NMkmxA4WsXhvwSKe3b8W"
	DeployNgrokTunnel(ctx, "ngroktunnel", Ngrok_Worker_PublicAddress, workerSvc, Ngrok_Auth_Token, Ngrok_Region, namespace)
}

func BoundaryDeployer(ctx *pulumi.Context, role string, ports corev1.ContainerPortArray, dependencies []pulumi.Resource, namespace *corev1.Namespace) *appsv1.Deployment {

	var livenessPort int
	// Use role to determine applabel
	appLabel := fmt.Sprintf("boundary-%v-pulumi", role)

	// Use role to determing config filename
	var configFileName string
	switch role {
	case "worker":
		configFileName = "worker.hcl"
		livenessPort = 9202
	case "controller":
		configFileName = "controller.hcl"
		livenessPort = 9200
	default:
		log.Fatalf("Role not supporrted: %s \n", role)
	}

	/*
		Before controller/worker Startup:
		- Self-signed certs are generated by Pulumi on deployment creation and stored as configMaps
		- Certs in configMaps are mounted to "/tls" folder

		On controller/worker startup:
		- Selfsigned certs on "/tls" are copied to "ca-certificates"
		- Run 'update-ca-certificates' to trust self signed certs.
	*/

	args := []string{strings.Join([]string{
		"cp -v /tls/boundary-worker.crt /usr/local/share/ca-certificates/",
		"cp -v /tls/boundary-controller.crt /usr/local/share/ca-certificates/",
		"update-ca-certificates",
		fmt.Sprintf("docker-entrypoint.sh server -config /boundary/%s", configFileName),
		//" while true; do echo Sleeping...; sleep 5; done",
	}, ";")}

	// Use boundary container from hashicorp
	cSpec := k8s.ContainerSpec{
		Name:  "boundary-controller",
		Image: fmt.Sprintf("%s:%s", boundaryImage, boundaryImageVersion),
		Command: []string{
			"/bin/sh",
			"-exc",
			"--",
		},
		Args:         args,
		LivenessPort: livenessPort,
	}

	// Define volume mounts for boundary controller
	volumes, volumeMounts := k8s.GetBoundaryMounts()

	// Define ENV vars for pod
	envVars := getEnvVars()

	// Define Tolerations for pod placement
	tolerations := k8s.GetTolerations()

	// Define security context
	securityContext := k8s.GetSecurityContext()

	deployment := k8s.CreateDeployment(ctx, appLabel, cSpec, ports, volumes, volumeMounts, envVars, tolerations, securityContext, dependencies, namespace)

	return deployment
}

func CreateConfigMaps(ctx *pulumi.Context, namespace *corev1.Namespace) {

	controllerFQDN := fmt.Sprintf("%s.%s", ControllerARecord, DnsZone)
	workerFQDN := fmt.Sprintf("%s.%s", WorkerARecord, DnsZone)

	// Provide inputs for rendering config file
	config := utils.BoundaryConfigFile{
		Controller_PublicClusterAddress: controllerFQDN,
		Worker_PublicAddress:            Ngrok_Worker_PublicAddress,
		Worker_Name:                     workerFQDN,
		Worker_Controllers:              controllerFQDN,
	}

	// Create config maps containing the HCL config file for the controller
	k8s.CreateConfigMapFromFile(ctx, "boundary-config-controller", "controller.hcl", "cfg/boundary-config-controller.hcl", config, namespace)
	k8s.CreateConfigMapFromFile(ctx, "boundary-config-worker", "worker.hcl", "cfg/boundary-config-worker.hcl", config, namespace)

	// Create config maps with SSL private key
	key := pulumi.Sprintf("%s", privateKey.PrivateKeyPem)
	k8s.CreateConfigMapKV(ctx, "boundary-key", "boundary.key", key, namespace)

	// Create config map with SSL cert
	crt := pulumi.Sprintf("%s", Controller_cert.CertPem)
	k8s.CreateConfigMapKV(ctx, "boundary-crt-controller", "boundary-controller.crt", crt, namespace)

	crt2 := pulumi.Sprintf("%s", Worker_cert.CertPem)
	k8s.CreateConfigMapKV(ctx, "boundary-crt-worker", "boundary-worker.crt", crt2, namespace)

}

func getEnvVars() corev1.EnvVarArray {

	return corev1.EnvVarArray{
		corev1.EnvVarArgs{
			Name:  pulumi.String("AZURE_TENANT_ID"),
			Value: pulumi.String(os.Getenv("AZURE_TENANT_ID")),
		},
		corev1.EnvVarArgs{
			Name:  pulumi.String("AZURE_CLIENT_ID"),
			Value: servicePrincipal.ApplicationId,
		},
		corev1.EnvVarArgs{
			Name:  pulumi.String("AZURE_CLIENT_SECRET"),
			Value: servicePrincipalPassword.Value,
		},
		corev1.EnvVarArgs{
			Name:  pulumi.String("AZUREKEYVAULT_WRAPPER_VAULT_NAME"),
			Value: myvault.Name,
		},
		corev1.EnvVarArgs{
			Name:  pulumi.String("SKIP_CHOWN"),
			Value: pulumi.String("true"),
		},
		corev1.EnvVarArgs{
			Name:  pulumi.String("BOUNDARY_POSTGRES_URL"),
			Value: PostgresUrl,
		},
		corev1.EnvVarArgs{
			Name:  pulumi.String("BOUNDARY_LOG_LEVEL"),
			Value: pulumi.String("debug"),
		},
	}
}
